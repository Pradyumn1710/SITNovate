{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "# from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "import functools\n",
    "# from ipdb import set_trace as ipdb\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {{{ imports \n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# # }}} \n",
    "# # {{{ langsmith keys \n",
    "# LANGCHAIN_TRACING_V2=os.getenv('LANGCHAIN_TRACING_V2')\n",
    "# LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGCHAIN_API_KEY=os.getenv('LANGCHAIN_API_KEY')\n",
    "# LANGCHAIN_PROJECT=os.getenv('LANGCHAIN_PROJECT')\n",
    "# # }}} \n",
    "# GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "# # llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "# llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', google_api_key=GEMINI_API_KEY, temperature=0.0)\n",
    "# # {{{  DEF: create_agent\n",
    "#                 # \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "#                 # \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{{ imports \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "load_dotenv()\n",
    "# }}} \n",
    "\n",
    "\n",
    "# Configure Ollama\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = ChatOllama(\n",
    "    model=\"llama 3.1\",\n",
    "    callback_manager=callback_manager,\n",
    "    temperature=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert researcher, collaborating with other assistant researchers, all skilled at researching private companies and producing informative, descriptive and factual analysis.\"\n",
    "                \" If you are unable to fully answer, that's okay, other assistant with different tools will\"\n",
    "                \" help with where you left off.\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{{ CLASS: AgentState \n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str\n",
    "    supervisor_invocations: int\n",
    "    finalizing: bool\n",
    "# }}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{{  DEF: agent_node\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    if name == \"research_supervisor\":\n",
    "        state[\"supervisor_invocations\"] += 1\n",
    "        if state[\"supervisor_invocations\"] > 5:\n",
    "            state[\"finalizing\"] = True \n",
    "    \n",
    "    if state['finalizing']:\n",
    "        state[\"messages\"].append(HumanMessage(content=\"Conclude research and compile all the information provided by other assistants and organize it as a company research report. Prefix the answer with 'FINAL ANSWER'.\"))\n",
    "\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "        \"supervisor_invocations\": state[\"supervisor_invocations\"],\n",
    "        \"finalizing\": state[\"finalizing\"],\n",
    "    }\n",
    "# }}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{{ create agents\n",
    "research_supervisor_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You are the the most senior and experienced private equity company research manager. You have a team of assistants - 'company_overview_research_agent', 'financial_research_agent', 'business_model_agent', 'key_products_or_services_researcher_agent'. For the company input, delegate each task to different assistants. Your task is to compile all the information provided by other assistants and organize it as a company research report. The final answer should include all the necessary information in well formatted manner.\"\n",
    ")\n",
    "research_supervisor_node = functools.partial(agent_node, agent=research_supervisor_agent, name=\"research_supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_overview_research_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You are a curious and passionate private equity researcher. You should provide accurate information about the company name input such that it covers the 'Company Overview' part of a research.\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=company_overview_research_agent, name=\"company_overview_researcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_research_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You are a skilled financial analyst skilled at researching and scraping financial information about private companies through publicly available data. For the company input, provide any relevant financial data about the company. If using tavily_tool, suffix search text with 'company financials'\",\n",
    ")\n",
    "financial_research_node = functools.partial(agent_node, agent=financial_research_agent, name=\"financial_researcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_model_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You are an expert consultant skilled at understanding business models of different companies. For the company input, provide accurate business model based on analysis.\"\n",
    ")\n",
    "business_model_research_node = functools.partial(agent_node, agent=business_model_agent, name=\"business_model_researcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_analysis_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You are an expert in competitor analysis. Identify and assess key competitors of the company input, providing strengths and weaknesses for each competitor.\"\n",
    ")\n",
    "competition_analysis_node = functools.partial(agent_node, agent=competition_analysis_agent, name=\"competition_analysis_agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_tool]\n",
    "tool_node = ToolNode(tools)\n",
    "# }}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {{{ DEF: router\n",
    "\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if state[\"finalizing\"]:\n",
    "        return \"__end__\"\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return \"__end__\"\n",
    "    return \"continue\"\n",
    "# }}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x73a0b9022490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"research_supervisor\", research_supervisor_node)\n",
    "workflow.add_node(\"company_overview_researcher\", research_node)\n",
    "workflow.add_node(\"financial_researcher\", financial_research_node)\n",
    "workflow.add_node(\"business_model_researcher\", business_model_research_node)\n",
    "workflow.add_node(\"competition_analysis_agent\", competition_analysis_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x73a0b9022490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"research_supervisor\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"research_supervisor\",\n",
    "    router,\n",
    "    {\"continue\": \"competition_analysis_agent\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"competition_analysis_agent\",\n",
    "    router,\n",
    "    {\"continue\": \"market_trends_agent\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"market_trends_agent\",\n",
    "    router,\n",
    "    {\"continue\": \"financial_analysis_agent\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"financial_analysis_agent\",\n",
    "    router,\n",
    "    {\"continue\": \"business_strategy_agent\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"business_strategy_agent\",\n",
    "    router,\n",
    "    {\"continue\": \"research_supervisor\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"research_supervisor\": \"research_supervisor\",\n",
    "        \"market_trends_agent\": \"market_trends_agent\",\n",
    "        \"financial_analysis_agent\": \"financial_analysis_agent\",\n",
    "        \"business_strategy_agent\": \"business_strategy_agent\",\n",
    "        \"competition_analysis_agent\": \"competition_analysis_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"research_supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Text, MetaData, Table\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1001226/3463034755.py:5: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "DATABASE_URL = \"postgresql+psycopg2://neutrino:123@localhost:5432/companyresearch\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "\n",
    "agent_responses_table = Table(\n",
    "    \"agent_responses\",\n",
    "    metadata,\n",
    "    Column(\"id\", Integer, primary_key=True, index=True),\n",
    "    Column(\"company_name\", String, index=True),\n",
    "    Column(\"competitor_analysis\", Text),\n",
    "    Column(\"market_trends\", Text),\n",
    "    Column(\"financial_analysis\", Text),\n",
    "    Column(\"business_strategy\", Text),\n",
    "    extend_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentResponse(Base):\n",
    "    __tablename__ = \"agent_responses\"\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    company_name = Column(String, index=True)\n",
    "    competitor_analysis = Column(Text)\n",
    "    market_trends = Column(Text)\n",
    "    financial_analysis = Column(Text)\n",
    "    business_strategy = Column(Text)\n",
    "\n",
    "Base.metadata.create_all(bind=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 13:45:54.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-25 13:45:54.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# company_name = 'Zerodha'\n",
    "# country_name = 'India'\n",
    "\n",
    "# {{{ streamlit \n",
    "\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "st.title(\"Company Research Assistant\")\n",
    "user_input_company_name = st.text_input(\"Enter company name:\", key=\"user_input\")\n",
    "\n",
    "query_prompt = f\"\"\"Research for company {user_input_company_name}. The research should include the following:\n",
    "1. Company Overview\n",
    "2. Company Financials\n",
    "3. Company Business Model\n",
    "4. Key Products/Services\n",
    "5. Competitor Analysis\n",
    "Once done, finish.\"\"\"\n",
    "\n",
    "if st.button(\"Submit\"):\n",
    "    if user_input_company_name:\n",
    "        output = graph.invoke({\"messages\": [HumanMessage(content=query_prompt)], \"supervisor_invocations\": 0, \"finalizing\": False}, {\"recursion_limit\": 150})\n",
    "        \n",
    "        st.session_state.chat_history.append({\"You\": user_input_company_name, \"Researcher\": output['messages'][-1].content})\n",
    "\n",
    "        st.session_state.user_input_company_name = \"\"\n",
    "\n",
    "for chat in st.session_state.chat_history:\n",
    "    st.write(f\"**You**: {chat['You']}\")\n",
    "    st.write(f\"**Researcher**: {chat['Researcher']}\")\n",
    "    st.write('---')\n",
    "\n",
    "# st.text_input(\"Enter company name\", key='user_input2', on_change=lambda: None)\n",
    "        \n",
    "# }}} \n",
    "\n",
    "# {{{ stream\n",
    "\n",
    "# events = graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(\n",
    "#                 content=\"Research for Indian company 'Zerodha' and share relevant company financial information. Once done, finish.\"\n",
    "#             )\n",
    "#         ],\n",
    "#     },\n",
    "#     # Maximum number of steps to take in the graph\n",
    "#     {\"recursion_limit\": 150},\n",
    "# )\n",
    "# for s in events:\n",
    "#     print(s)\n",
    "#     print(\"----\")\n",
    "# }}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
